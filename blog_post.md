# What is "Learning" for Neural Networks

Here at Fast Forward Labs, we've been hard at work researching and producing deep neural networks for object recognition. You may have seen our prototype [pictograph](www.pictograph.us), or run into neural networks through [other recent trends](http://googleresearch.blogspot.ch/2015/06/inceptionism-going-deeper-into-neural.html). These cutting-edge systems are blowing up due to new emergence in complimentary technologies and great success, specifically in the realms of image and speech data.

Whether you are an engineer or a layman, something you'll quickly run into is the great complexity of neural networks. A question that may be striking is, "What does it mean for a neural network to learn?" Recently, Google [released a video](https://www.youtube.com/watch?v=bHvf7Tagt18&index=11&list=PLeqAcoTy5741GXa8rccolGQaj_nVGw76g) that helps the layperson understand some of the basics of machine learning and neural networks. One of the conclusions is: it's hard to teach computers things, and it's impressive how good humans are at learning!

But what is the comparison here? How are neural networks learning and is it comparable to human learning systems?

Since this question of learning is at the heart of AI for both engineers and enthusiasts, it felt the time was right to dive a bit "deeper".

Remember:

- used softmax
- did not do any regularization or dropout; mini-batching neither
- Watch the activation nearest the target,if you backprop > forward, you'll see the learning.
- Emergence (ie, emergent behaviors of dynamic system)
- Staring at any particular number can't help you
- Could've been more freedom, but restriction helps in the learning of a particular idea.